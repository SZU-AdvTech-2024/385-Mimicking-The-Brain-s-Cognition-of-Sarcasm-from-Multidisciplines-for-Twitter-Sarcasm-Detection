-------------------------------hyperparameters---------------------------
lr: 0.0001, batch-size: 64, 
-------------------------------------------------------------------------
**train** epoch 0, train_acc: 0.9084578118691966, train_loss: 48.128318786621094, test_acc: 0.8887505188875052, test_P: 0.9003476245654692, test_R: 0.8102189781021898, test_F1: 0.8529088913282108
**train** epoch 1, train_acc: 0.9599818328623335, train_loss: 24.819162368774414, test_acc: 0.9219593192195932, test_P: 0.8921668362156663, test_R: 0.9144942648592284, test_F1: 0.9031925849639547
**train** epoch 2, train_acc: 0.9610415825595479, train_loss: 21.26279067993164, test_acc: 0.9161477791614778, test_P: 0.8980021030494216, test_R: 0.8905109489051095, test_F1: 0.8942408376963351
**train** epoch 3, train_acc: 0.9627573677836092, train_loss: 19.86968421936035, test_acc: 0.91697799916978, test_P: 0.8940809968847352, test_R: 0.8978102189781022, test_F1: 0.8959417273673257
**train** epoch 4, train_acc: 0.9650787242632216, train_loss: 19.368005752563477, test_acc: 0.912826899128269, test_P: 0.898828541001065, test_R: 0.8800834202294057, test_F1: 0.8893572181243414
**train** epoch 5, train_acc: 0.9679047234557933, train_loss: 16.564565658569336, test_acc: 0.9161477791614778, test_P: 0.8707149853085211, test_R: 0.927007299270073, test_F1: 0.897979797979798
