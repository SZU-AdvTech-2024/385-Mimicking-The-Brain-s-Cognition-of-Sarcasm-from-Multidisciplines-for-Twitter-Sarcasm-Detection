-------------------------------hyperparameters---------------------------
lr: 0.0001, temp: 0.8, cl-weight: 0.1, bce-weight:0.9 batch-size: 64, 
-------------------------------------------------------------------------
**train** epoch 0, train_acc: 0.6834880904319741, train_loss: 318.4601135253906, test_acc: 0.7065172270651723, test_P: 0.6503579952267303, test_R: 0.5683003128258602, test_F1: 0.6065664997217585
**train** epoch 1, train_acc: 0.712858296326201, train_loss: 308.8898010253906, test_acc: 0.709838107098381, test_P: 0.631578947368421, test_R: 0.6506777893639207, test_F1: 0.6409861325115562
**train** epoch 2, train_acc: 0.7240109002826, train_loss: 304.8246765136719, test_acc: 0.7090078870900789, test_P: 0.6187845303867403, test_R: 0.7007299270072993, test_F1: 0.6572127139364303
**train** epoch 3, train_acc: 0.736324182478805, train_loss: 298.60223388671875, test_acc: 0.7202158572021585, test_P: 0.6801517067003793, test_R: 0.5610010427528676, test_F1: 0.6148571428571429
**train** epoch 4, train_acc: 0.7515643924101736, train_loss: 293.01953125, test_acc: 0.7081776670817767, test_P: 0.6157323688969258, test_R: 0.7101147028154328, test_F1: 0.6595641646489104
**train** epoch 5, train_acc: 0.7658962454582156, train_loss: 287.5785217285156, test_acc: 0.7135740971357409, test_P: 0.6232813932172319, test_R: 0.7090719499478624, test_F1: 0.6634146341463415
**train** epoch 6, train_acc: 0.7819943480016148, train_loss: 279.9840087890625, test_acc: 0.7015359070153591, test_P: 0.6038062283737025, test_R: 0.7278415015641293, test_F1: 0.660047281323877
**train** epoch 7, train_acc: 0.8045518772708922, train_loss: 271.4630432128906, test_acc: 0.6928185969281859, test_P: 0.6003666361136571, test_R: 0.6830031282586028, test_F1: 0.6390243902439025
**train** epoch 8, train_acc: 0.8210536939846589, train_loss: 262.2469177246094, test_acc: 0.7102532171025322, test_P: 0.6375131717597471, test_R: 0.6308654848800834, test_F1: 0.6341719077568134
**train** epoch 9, train_acc: 0.8386657246669358, train_loss: 251.75550842285156, test_acc: 0.6990452469904525, test_P: 0.6087360594795539, test_R: 0.6830031282586028, test_F1: 0.6437346437346437
**train** epoch 10, train_acc: 0.8576907549454986, train_loss: 240.70594787597656, test_acc: 0.6928185969281859, test_P: 0.5976806422836753, test_R: 0.6986444212721585, test_F1: 0.6442307692307693
**train** epoch 11, train_acc: 0.8799959628582963, train_loss: 230.1572265625, test_acc: 0.6874221668742216, test_P: 0.5969868173258004, test_R: 0.6611053180396246, test_F1: 0.6274121721919842
**train** epoch 12, train_acc: 0.891905530884134, train_loss: 222.4501495361328, test_acc: 0.6820257368202574, test_P: 0.6438152011922503, test_R: 0.4504692387904067, test_F1: 0.5300613496932516
