-------------------------------hyperparameters---------------------------
lr: 0.0001, temp: 0.6, cl-weight: 0.1, bce-weight:0.9 batch-size: 64, 
-------------------------------------------------------------------------
**train** epoch 0, train_acc: 0.6833366976180864, train_loss: 318.6839294433594, test_acc: 0.7031963470319634, test_P: 0.6380090497737556, test_R: 0.5881126173096975, test_F1: 0.6120455778621813
**train** epoch 1, train_acc: 0.710284618490109, train_loss: 309.23687744140625, test_acc: 0.7069323370693233, test_P: 0.6284263959390863, test_R: 0.6454640250260688, test_F1: 0.6368312757201646
**train** epoch 2, train_acc: 0.7222446507872426, train_loss: 305.2509765625, test_acc: 0.7114985471149855, test_P: 0.6206581352833638, test_R: 0.708029197080292, test_F1: 0.6614710180224063
**train** epoch 3, train_acc: 0.7353653613241825, train_loss: 299.18145751953125, test_acc: 0.7123287671232876, test_P: 0.675, test_R: 0.5349322210636079, test_F1: 0.5968586387434555
**train** epoch 4, train_acc: 0.750656035526847, train_loss: 293.797607421875, test_acc: 0.70568700705687, test_P: 0.6114081996434938, test_R: 0.7153284671532847, test_F1: 0.6592984142239308
**train** epoch 5, train_acc: 0.7629693177230521, train_loss: 288.77874755859375, test_acc: 0.7069323370693233, test_P: 0.6122448979591837, test_R: 0.7194994786235662, test_F1: 0.6615532118887824
**train** epoch 6, train_acc: 0.7774525635849818, train_loss: 281.91357421875, test_acc: 0.696969696969697, test_P: 0.59439406430338, test_R: 0.7518248175182481, test_F1: 0.6639042357274402
**train** epoch 7, train_acc: 0.798193379087606, train_loss: 273.4449462890625, test_acc: 0.6878372768783728, test_P: 0.5962790697674418, test_R: 0.6684045881126173, test_F1: 0.6302851524090463
**train** epoch 8, train_acc: 0.8145438029874849, train_loss: 264.8907775878906, test_acc: 0.7077625570776256, test_P: 0.6349206349206349, test_R: 0.6256517205422315, test_F1: 0.6302521008403361
**train** epoch 9, train_acc: 0.8363443681873234, train_loss: 254.26132202148438, test_acc: 0.7023661270236613, test_P: 0.623721881390593, test_R: 0.6360792492179353, test_F1: 0.6298399586990191
**train** epoch 10, train_acc: 0.8529975777149778, train_loss: 244.4026641845703, test_acc: 0.6911581569115816, test_P: 0.6172300981461287, test_R: 0.5901981230448383, test_F1: 0.603411513859275
**train** epoch 11, train_acc: 0.8760092854259185, train_loss: 233.68833923339844, test_acc: 0.6919883769198838, test_P: 0.5987261146496815, test_R: 0.6861313868613139, test_F1: 0.6394557823129252
**train** epoch 12, train_acc: 0.8836798546628987, train_loss: 227.31137084960938, test_acc: 0.6919883769198838, test_P: 0.6607407407407407, test_R: 0.46506777893639206, test_F1: 0.5458996328029376
