-------------------------------hyperparameters---------------------------
lr: 0.0001, temp: 0.4, cl-weight: 0.2, bce-weight:0.8 batch-size: 64, 
-------------------------------------------------------------------------
**train** epoch 0, train_acc: 0.681671376665321, train_loss: 452.1946716308594, test_acc: 0.6915732669157326, test_P: 0.6189427312775331, test_R: 0.5860271115745568, test_F1: 0.6020353508302089
**train** epoch 1, train_acc: 0.7065502624142107, train_loss: 443.8603515625, test_acc: 0.6982150269821503, test_P: 0.6141732283464567, test_R: 0.6506777893639207, test_F1: 0.6318987341772152
**train** epoch 2, train_acc: 0.7150787242632216, train_loss: 440.1625671386719, test_acc: 0.7139892071398921, test_P: 0.6216216216216216, test_R: 0.7194994786235662, test_F1: 0.6669888835186081
**train** epoch 3, train_acc: 0.7277452563584982, train_loss: 432.38226318359375, test_acc: 0.7148194271481942, test_P: 0.6823056300268097, test_R: 0.5307612095933264, test_F1: 0.5970674486803519
**train** epoch 4, train_acc: 0.7425312878482034, train_loss: 424.596923828125, test_acc: 0.6977999169779991, test_P: 0.5977984758679086, test_R: 0.7361835245046924, test_F1: 0.6598130841121496
**train** epoch 5, train_acc: 0.7546931772305208, train_loss: 418.2218017578125, test_acc: 0.7019510170195101, test_P: 0.6016877637130802, test_R: 0.7434827945776851, test_F1: 0.6651119402985075
**train** epoch 6, train_acc: 0.7718005651998385, train_loss: 411.7012023925781, test_acc: 0.7040265670402657, test_P: 0.6071428571428571, test_R: 0.7267987486965589, test_F1: 0.6616041765543427
**train** epoch 7, train_acc: 0.7861324182478805, train_loss: 404.1814270019531, test_acc: 0.6998754669987547, test_P: 0.6143410852713178, test_R: 0.6611053180396246, test_F1: 0.6368658965344048
**train** epoch 8, train_acc: 0.8048041986273718, train_loss: 395.5556945800781, test_acc: 0.7040265670402657, test_P: 0.6189555125725339, test_R: 0.6673618352450469, test_F1: 0.6422478675363773
**train** epoch 9, train_acc: 0.8271598708114655, train_loss: 386.5069885253906, test_acc: 0.7144043171440432, test_P: 0.6296650717703349, test_R: 0.6861313868613139, test_F1: 0.656686626746507
**train** epoch 10, train_acc: 0.8397759386354461, train_loss: 377.2907409667969, test_acc: 0.6778746367787464, test_P: 0.5724465558194775, test_R: 0.7539103232533889, test_F1: 0.6507650765076508
**train** epoch 11, train_acc: 0.8623334679047234, train_loss: 366.7294006347656, test_acc: 0.6911581569115816, test_P: 0.599444958371878, test_R: 0.67570385818561, test_F1: 0.6352941176470588
**train** epoch 12, train_acc: 0.8721235365361324, train_loss: 361.36041259765625, test_acc: 0.6944790369447904, test_P: 0.6718027734976888, test_R: 0.4546402502606882, test_F1: 0.5422885572139303
