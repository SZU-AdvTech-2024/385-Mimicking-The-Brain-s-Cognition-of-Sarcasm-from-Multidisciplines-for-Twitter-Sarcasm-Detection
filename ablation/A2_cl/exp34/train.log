-------------------------------hyperparameters---------------------------
lr: 0.0001, temp: 0.8, cl-weight: 0.2, bce-weight:0.8 batch-size: 64, 
-------------------------------------------------------------------------
**train** epoch 0, train_acc: 0.6846487686717804, train_loss: 450.8679504394531, test_acc: 0.7031963470319634, test_P: 0.6386363636363637, test_R: 0.5860271115745568, test_F1: 0.6112017400761284
**train** epoch 1, train_acc: 0.711596689543803, train_loss: 442.496826171875, test_acc: 0.7044416770444167, test_P: 0.6233766233766234, test_R: 0.6506777893639207, test_F1: 0.636734693877551
**train** epoch 2, train_acc: 0.7211849010900283, train_loss: 439.1392517089844, test_acc: 0.7069323370693233, test_P: 0.6104803493449782, test_R: 0.7288842544316997, test_F1: 0.6644486692015209
**train** epoch 3, train_acc: 0.7320851836899476, train_loss: 434.0897216796875, test_acc: 0.7106683271066833, test_P: 0.6794520547945205, test_R: 0.5172054223149114, test_F1: 0.5873297809354647
**train** epoch 4, train_acc: 0.7473253936213161, train_loss: 429.5738830566406, test_acc: 0.7061021170610212, test_P: 0.6119536128456735, test_R: 0.7153284671532847, test_F1: 0.6596153846153846
**train** epoch 5, train_acc: 0.7579733548647557, train_loss: 425.3516845703125, test_acc: 0.7069323370693233, test_P: 0.6120460584588131, test_R: 0.7205422314911366, test_F1: 0.6618773946360154
**train** epoch 6, train_acc: 0.7724061364553896, train_loss: 419.4579162597656, test_acc: 0.6977999169779991, test_P: 0.5963302752293578, test_R: 0.7455683003128258, test_F1: 0.6626506024096386
**train** epoch 7, train_acc: 0.7917339523617279, train_loss: 411.6590881347656, test_acc: 0.6982150269821503, test_P: 0.6039426523297491, test_R: 0.7028154327424401, test_F1: 0.6496385542168674
**train** epoch 8, train_acc: 0.8092955187727089, train_loss: 402.36492919921875, test_acc: 0.6986301369863014, test_P: 0.6035555555555555, test_R: 0.708029197080292, test_F1: 0.6516314779270633
**train** epoch 9, train_acc: 0.8276140492531288, train_loss: 393.4114990234375, test_acc: 0.7123287671232876, test_P: 0.6405919661733616, test_R: 0.6319082377476538, test_F1: 0.6362204724409449
**train** epoch 10, train_acc: 0.8475474364150182, train_loss: 384.0316162109375, test_acc: 0.6961394769613948, test_P: 0.6081982840800763, test_R: 0.6652763295099061, test_F1: 0.6354581673306773
**train** epoch 11, train_acc: 0.8680863948324586, train_loss: 373.9122009277344, test_acc: 0.6874221668742216, test_P: 0.5894097222222222, test_R: 0.708029197080292, test_F1: 0.6432970156324017
**train** epoch 12, train_acc: 0.874343964473153, train_loss: 369.3020935058594, test_acc: 0.6716479867164799, test_P: 0.6584905660377358, test_R: 0.36392075078206465, test_F1: 0.46877098723975824
