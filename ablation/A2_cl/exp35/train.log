-------------------------------hyperparameters---------------------------
lr: 0.0001, temp: 0.8, cl-weight: 0.4, bce-weight:1.0 batch-size: 64, 
-------------------------------------------------------------------------
**train** epoch 0, train_acc: 0.6837908760597498, train_loss: 789.8928833007812, test_acc: 0.6961394769613948, test_P: 0.6265328874024526, test_R: 0.5860271115745568, test_F1: 0.6056034482758621
**train** epoch 1, train_acc: 0.7086697618086395, train_loss: 779.7186889648438, test_acc: 0.7007056870070568, test_P: 0.6197183098591549, test_R: 0.6423357664233577, test_F1: 0.6308243727598566
**train** epoch 2, train_acc: 0.7179551877270892, train_loss: 775.447509765625, test_acc: 0.7061021170610212, test_P: 0.6086580086580087, test_R: 0.7330552659019812, test_F1: 0.6650898770104068
**train** epoch 3, train_acc: 0.729814291481631, train_loss: 767.5007934570312, test_acc: 0.7110834371108343, test_P: 0.6953937592867756, test_R: 0.4880083420229406, test_F1: 0.5735294117647058
**train** epoch 4, train_acc: 0.7457610012111425, train_loss: 755.6004028320312, test_acc: 0.7007056870070568, test_P: 0.6011904761904762, test_R: 0.7372262773722628, test_F1: 0.6622950819672131
**train** epoch 5, train_acc: 0.7576705692369802, train_loss: 745.5880737304688, test_acc: 0.7048567870485679, test_P: 0.6067125645438899, test_R: 0.735140771637122, test_F1: 0.6647807637906648
**train** epoch 6, train_acc: 0.7691259588211546, train_loss: 736.3972778320312, test_acc: 0.7106683271066833, test_P: 0.6228893058161351, test_R: 0.6923879040667362, test_F1: 0.6558024691358024
**train** epoch 7, train_acc: 0.7868389180460235, train_loss: 727.443359375, test_acc: 0.6953092569530925, test_P: 0.6070409134157945, test_R: 0.6652763295099061, test_F1: 0.6348258706467662
**train** epoch 8, train_acc: 0.8053088413403311, train_loss: 717.2763061523438, test_acc: 0.7185554171855542, test_P: 0.6376101860920667, test_R: 0.6788321167883211, test_F1: 0.6575757575757576
**train** epoch 9, train_acc: 0.8210032297133629, train_loss: 706.5438232421875, test_acc: 0.7069323370693233, test_P: 0.6161616161616161, test_R: 0.6996871741397289, test_F1: 0.6552734375
**train** epoch 10, train_acc: 0.8368490109002826, train_loss: 696.3463134765625, test_acc: 0.6977999169779991, test_P: 0.6086547507055503, test_R: 0.6746611053180396, test_F1: 0.6399604352126608
**train** epoch 11, train_acc: 0.8574888978603149, train_loss: 685.0872192382812, test_acc: 0.680365296803653, test_P: 0.585675430643699, test_R: 0.6736183524504692, test_F1: 0.6265761396702231
**train** epoch 12, train_acc: 0.8618288251917642, train_loss: 678.6709594726562, test_acc: 0.6961394769613948, test_P: 0.6642547033285094, test_R: 0.4786235662148071, test_F1: 0.5563636363636364
