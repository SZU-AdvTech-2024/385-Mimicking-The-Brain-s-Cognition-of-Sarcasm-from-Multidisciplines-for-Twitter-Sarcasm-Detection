-------------------------------hyperparameters---------------------------
lr: 0.0001, temp: 0.2, cl-weight: 0.1, bce-weight:1.0 batch-size: 64, 
-------------------------------------------------------------------------
**train** epoch 0, train_acc: 0.6800565199838514, train_loss: 339.8706970214844, test_acc: 0.6924034869240349, test_P: 0.620575221238938, test_R: 0.5849843587069864, test_F1: 0.6022544283413849
**train** epoch 1, train_acc: 0.7055914412595882, train_loss: 329.37481689453125, test_acc: 0.7015359070153591, test_P: 0.6149425287356322, test_R: 0.6694473409801877, test_F1: 0.6410384423364952
**train** epoch 2, train_acc: 0.7144731530076706, train_loss: 325.20947265625, test_acc: 0.7077625570776256, test_P: 0.6129317980513729, test_R: 0.721584984358707, test_F1: 0.6628352490421456
**train** epoch 3, train_acc: 0.7267864352038756, train_loss: 318.83587646484375, test_acc: 0.7144043171440432, test_P: 0.6757457846952011, test_R: 0.543274244004171, test_F1: 0.6023121387283237
**train** epoch 4, train_acc: 0.7432882519176424, train_loss: 311.46282958984375, test_acc: 0.70942299709423, test_P: 0.6176203451407811, test_R: 0.7090719499478624, test_F1: 0.6601941747572816
**train** epoch 5, train_acc: 0.755147355672184, train_loss: 304.7830810546875, test_acc: 0.7131589871315899, test_P: 0.6231617647058824, test_R: 0.7069864442127216, test_F1: 0.6624328285295554
**train** epoch 6, train_acc: 0.7687727089220832, train_loss: 297.28558349609375, test_acc: 0.7081776670817767, test_P: 0.6180811808118081, test_R: 0.6986444212721585, test_F1: 0.6558981889378365
**train** epoch 7, train_acc: 0.7856277755349212, train_loss: 289.0011291503906, test_acc: 0.7036114570361146, test_P: 0.6131117266851339, test_R: 0.6923879040667362, test_F1: 0.6503428011753183
**train** epoch 8, train_acc: 0.8047537343560759, train_loss: 279.3002624511719, test_acc: 0.7061021170610212, test_P: 0.6196377502383222, test_R: 0.6777893639207507, test_F1: 0.647410358565737
**train** epoch 9, train_acc: 0.8261505853855471, train_loss: 268.4961853027344, test_acc: 0.7081776670817767, test_P: 0.626984126984127, test_R: 0.6590198123044838, test_F1: 0.6426029486527707
**train** epoch 10, train_acc: 0.8389685102947113, train_loss: 257.9720764160156, test_acc: 0.7007056870070568, test_P: 0.6322222222222222, test_R: 0.5933263816475496, test_F1: 0.6121570736955352
**train** epoch 11, train_acc: 0.8647557529269277, train_loss: 245.0477752685547, test_acc: 0.6903279369032793, test_P: 0.6336260978670013, test_R: 0.5265901981230449, test_F1: 0.5751708428246014
**train** epoch 12, train_acc: 0.8751009285425918, train_loss: 235.72286987304688, test_acc: 0.684516396845164, test_P: 0.6736474694589878, test_R: 0.40250260688216893, test_F1: 0.5039164490861618
