-------------------------------hyperparameters---------------------------
lr: 0.0001, batch-size: 64, 
-------------------------------------------------------------------------
**train** epoch 0, train_acc: 0.6759689140088817, train_loss: 1698.53173828125, test_acc: 0.6890826068908261, test_P: 0.6124197002141327, test_R: 0.5964546402502607, test_F1: 0.6043317485472794
**train** epoch 1, train_acc: 0.7000403714170368, train_loss: 1682.6044921875, test_acc: 0.6998754669987547, test_P: 0.6094619666048238, test_R: 0.6850886339937435, test_F1: 0.6450662739322534
**train** epoch 2, train_acc: 0.7174000807428341, train_loss: 1653.44775390625, test_acc: 0.6977999169779991, test_P: 0.6005221932114883, test_R: 0.7194994786235662, test_F1: 0.6546489563567363
**train** epoch 3, train_acc: 0.7260294711344368, train_loss: 1627.8592529296875, test_acc: 0.7160647571606475, test_P: 0.6589595375722543, test_R: 0.59436913451512, test_F1: 0.625
**train** epoch 4, train_acc: 0.7436415018167137, train_loss: 1604.7373046875, test_acc: 0.7152345371523454, test_P: 0.6355511420059583, test_R: 0.6673618352450469, test_F1: 0.6510681586978637
**train** epoch 5, train_acc: 0.7501513928138878, train_loss: 1583.6876220703125, test_acc: 0.709838107098381, test_P: 0.6146384479717814, test_R: 0.7267987486965589, test_F1: 0.6660296225513617
**train** epoch 6, train_acc: 0.7625151392813888, train_loss: 1567.19921875, test_acc: 0.7181403071814031, test_P: 0.6313320825515948, test_R: 0.7017726798748697, test_F1: 0.6646913580246914
**train** epoch 7, train_acc: 0.771497779572063, train_loss: 1548.62060546875, test_acc: 0.6953092569530925, test_P: 0.6005361930294906, test_R: 0.7007299270072993, test_F1: 0.6467757459095284
