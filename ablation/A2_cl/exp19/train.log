-------------------------------hyperparameters---------------------------
lr: 0.0001, temp: 0.4, cl-weight: 0.4, bce-weight:0.6 batch-size: 64, 
-------------------------------------------------------------------------
**train** epoch 0, train_acc: 0.6763221639079532, train_loss: 717.8135986328125, test_acc: 0.6894977168949772, test_P: 0.6114044350580782, test_R: 0.6037539103232534, test_F1: 0.6075550891920252
**train** epoch 1, train_acc: 0.7003431570448123, train_loss: 709.2655029296875, test_acc: 0.6977999169779991, test_P: 0.6156156156156156, test_R: 0.6412930135557873, test_F1: 0.6281920326864147
**train** epoch 2, train_acc: 0.7150787242632216, train_loss: 699.2904663085938, test_acc: 0.7069323370693233, test_P: 0.6106736657917761, test_R: 0.7278415015641293, test_F1: 0.6641294005708849
**train** epoch 3, train_acc: 0.7251211142511103, train_loss: 686.6348876953125, test_acc: 0.7181403071814031, test_P: 0.6647058823529411, test_R: 0.5891553701772679, test_F1: 0.6246545052515202
**train** epoch 4, train_acc: 0.7431873233750504, train_loss: 676.8634033203125, test_acc: 0.7139892071398921, test_P: 0.6285714285714286, test_R: 0.6882168925964547, test_F1: 0.6570433051269288
**train** epoch 5, train_acc: 0.750656035526847, train_loss: 666.733642578125, test_acc: 0.7077625570776256, test_P: 0.6103896103896104, test_R: 0.735140771637122, test_F1: 0.6669820245979187
**train** epoch 6, train_acc: 0.7658457811869197, train_loss: 658.0877075195312, test_acc: 0.7123287671232876, test_P: 0.6206896551724138, test_R: 0.7132429614181439, test_F1: 0.6637554585152838
**train** epoch 7, train_acc: 0.7757872426322164, train_loss: 649.1248779296875, test_acc: 0.6977999169779991, test_P: 0.6021220159151194, test_R: 0.7101147028154328, test_F1: 0.6516746411483254
**train** epoch 8, train_acc: 0.7917844166330238, train_loss: 639.8717651367188, test_acc: 0.7144043171440432, test_P: 0.6364551863041289, test_R: 0.6590198123044838, test_F1: 0.6475409836065574
**train** epoch 9, train_acc: 0.8099010900282599, train_loss: 631.8217163085938, test_acc: 0.7085927770859277, test_P: 0.617781851512374, test_R: 0.7028154327424401, test_F1: 0.6575609756097561
**train** epoch 10, train_acc: 0.8178239806217198, train_loss: 625.0701293945312, test_acc: 0.696969696969697, test_P: 0.6039963669391463, test_R: 0.6934306569343066, test_F1: 0.6456310679611651
**train** epoch 11, train_acc: 0.8360415825595479, train_loss: 617.16552734375, test_acc: 0.6924034869240349, test_P: 0.6167023554603854, test_R: 0.6006256517205423, test_F1: 0.6085578446909667
**train** epoch 12, train_acc: 0.8462858296326201, train_loss: 612.2018432617188, test_acc: 0.7023661270236613, test_P: 0.6657534246575343, test_R: 0.5067778936392076, test_F1: 0.5754884547069272
