-------------------------------hyperparameters---------------------------
lr: 0.0001, temp: 0.6, cl-weight: 0.4, bce-weight:0.6 batch-size: 64, 
-------------------------------------------------------------------------
**train** epoch 0, train_acc: 0.6788958417440453, train_loss: 716.2120971679688, test_acc: 0.6940639269406392, test_P: 0.6203904555314533, test_R: 0.5964546402502607, test_F1: 0.6081871345029239
**train** epoch 1, train_acc: 0.7033710133225676, train_loss: 709.1483764648438, test_acc: 0.6998754669987547, test_P: 0.616370808678501, test_R: 0.6517205422314911, test_F1: 0.6335529650278763
**train** epoch 2, train_acc: 0.7153310456197013, train_loss: 701.8681030273438, test_acc: 0.7081776670817767, test_P: 0.6157323688969258, test_R: 0.7101147028154328, test_F1: 0.6595641646489104
**train** epoch 3, train_acc: 0.725928542591845, train_loss: 688.5767211914062, test_acc: 0.7231216272312163, test_P: 0.6640449438202247, test_R: 0.616266944734098, test_F1: 0.6392644672796106
**train** epoch 4, train_acc: 0.7423294307630198, train_loss: 680.6029052734375, test_acc: 0.7152345371523454, test_P: 0.627689429373246, test_R: 0.6996871741397289, test_F1: 0.6617357001972387
**train** epoch 5, train_acc: 0.7521194993944288, train_loss: 672.9653930664062, test_acc: 0.7061021170610212, test_P: 0.6115555555555555, test_R: 0.7174139728884255, test_F1: 0.6602687140115163
**train** epoch 6, train_acc: 0.7667036737989503, train_loss: 665.6609497070312, test_acc: 0.7106683271066833, test_P: 0.6175942549371634, test_R: 0.7174139728884255, test_F1: 0.6637723106608779
**train** epoch 7, train_acc: 0.7787646346386758, train_loss: 658.1002807617188, test_acc: 0.6994603569946035, test_P: 0.6130895091434071, test_R: 0.6642335766423357, test_F1: 0.6376376376376376
**train** epoch 8, train_acc: 0.7924909164311668, train_loss: 650.3634643554688, test_acc: 0.7090078870900789, test_P: 0.6303030303030303, test_R: 0.6506777893639207, test_F1: 0.6403283735248846
**train** epoch 9, train_acc: 0.8140391602745256, train_loss: 642.8480834960938, test_acc: 0.7102532171025322, test_P: 0.6360792492179353, test_R: 0.6360792492179353, test_F1: 0.6360792492179353
**train** epoch 10, train_acc: 0.8215583366976181, train_loss: 635.7115478515625, test_acc: 0.705271897052719, test_P: 0.6279547790339157, test_R: 0.6371220020855057, test_F1: 0.6325051759834368
**train** epoch 11, train_acc: 0.8407347597900686, train_loss: 627.7332153320312, test_acc: 0.6977999169779991, test_P: 0.6326061997703789, test_R: 0.5745568300312826, test_F1: 0.6021857923497268
**train** epoch 12, train_acc: 0.8481530076705692, train_loss: 623.0956420898438, test_acc: 0.7019510170195101, test_P: 0.6579292267365662, test_R: 0.5234619395203337, test_F1: 0.5830429732868757
