-------------------------------hyperparameters---------------------------
lr: 0.0001, temp: 0.2, cl-weight: 0.2, bce-weight:0.8 batch-size: 64, 
-------------------------------------------------------------------------
**train** epoch 0, train_acc: 0.6861122325393622, train_loss: 147.5923614501953, test_acc: 0.7027812370278124, test_P: 0.651307596513076, test_R: 0.5453597497393118, test_F1: 0.5936435868331441
**train** epoch 1, train_acc: 0.7138675817521195, train_loss: 139.10836791992188, test_acc: 0.7061021170610212, test_P: 0.6311389759665622, test_R: 0.629822732012513, test_F1: 0.6304801670146137
**train** epoch 2, train_acc: 0.7294105773112636, train_loss: 134.3728485107422, test_acc: 0.7102532171025322, test_P: 0.6220767072029935, test_R: 0.6934306569343066, test_F1: 0.6558185404339251
**train** epoch 3, train_acc: 0.7426826806620912, train_loss: 127.90215301513672, test_acc: 0.7127438771274388, test_P: 0.6683480453972257, test_R: 0.5526590198123045, test_F1: 0.6050228310502284
**train** epoch 4, train_acc: 0.7599414614452967, train_loss: 121.85382080078125, test_acc: 0.7061021170610212, test_P: 0.612354521038496, test_R: 0.7132429614181439, test_F1: 0.6589595375722543
**train** epoch 5, train_acc: 0.7739705288655632, train_loss: 114.5760269165039, test_acc: 0.7085927770859277, test_P: 0.6167120799273388, test_R: 0.708029197080292, test_F1: 0.6592233009708738
**train** epoch 6, train_acc: 0.7936515946709729, train_loss: 106.18900299072266, test_acc: 0.6899128268991283, test_P: 0.5832025117739403, test_R: 0.7747653806047967, test_F1: 0.6654724585759069
**train** epoch 7, train_acc: 0.8138877674606378, train_loss: 96.93954467773438, test_acc: 0.6861768368617683, test_P: 0.5850796311818944, test_R: 0.7278415015641293, test_F1: 0.6486988847583643
**train** epoch 8, train_acc: 0.833366976180864, train_loss: 88.3758773803711, test_acc: 0.7031963470319634, test_P: 0.621031746031746, test_R: 0.6527632950990615, test_F1: 0.6365022877478393
**train** epoch 9, train_acc: 0.8547133629390392, train_loss: 79.30367279052734, test_acc: 0.7081776670817767, test_P: 0.6189591078066915, test_R: 0.694473409801877, test_F1: 0.6545454545454545
**train** epoch 10, train_acc: 0.8741925716592652, train_loss: 68.30693054199219, test_acc: 0.6919883769198838, test_P: 0.6030389363722697, test_R: 0.662148070907195, test_F1: 0.6312127236580517
**train** epoch 11, train_acc: 0.8914513524424708, train_loss: 58.929588317871094, test_acc: 0.6944790369447904, test_P: 0.6044985941893158, test_R: 0.6725755995828988, test_F1: 0.6367226061204343
**train** epoch 12, train_acc: 0.899727492935002, train_loss: 53.678890228271484, test_acc: 0.6907430469074305, test_P: 0.6621212121212121, test_R: 0.4556830031282586, test_F1: 0.5398394070413836
**train** epoch 13, train_acc: 0.9161788453774727, train_loss: 45.59785079956055, test_acc: 0.6911581569115816, test_P: 0.6095820591233435, test_R: 0.6235662148070907, test_F1: 0.6164948453608248
**train** epoch 14, train_acc: 0.9278865563181268, train_loss: 39.37006378173828, test_acc: 0.6870070568700706, test_P: 0.6279650436953808, test_R: 0.5245046923879041, test_F1: 0.571590909090909
**train** epoch 15, train_acc: 0.9307630197819944, train_loss: 36.622528076171875, test_acc: 0.7077625570776256, test_P: 0.6418242491657397, test_R: 0.6016684045881127, test_F1: 0.6210979547900969
**train** epoch 16, train_acc: 0.9440855874041179, train_loss: 30.607563018798828, test_acc: 0.6774595267745953, test_P: 0.5858490566037736, test_R: 0.6475495307612096, test_F1: 0.6151560178306092
**train** epoch 17, train_acc: 0.9425211949939443, train_loss: 30.441816329956055, test_acc: 0.6857617268576173, test_P: 0.5933456561922366, test_R: 0.6694473409801877, test_F1: 0.6291033806957373
**train** epoch 18, train_acc: 0.9453976584578119, train_loss: 29.1240291595459, test_acc: 0.7065172270651723, test_P: 0.6326315789473684, test_R: 0.6266944734098019, test_F1: 0.6296490309062336
**train** epoch 19, train_acc: 0.9543298344771901, train_loss: 24.070003509521484, test_acc: 0.6766293067662931, test_P: 0.5833333333333334, test_R: 0.656934306569343, test_F1: 0.6179499754781755
**train** epoch 20, train_acc: 0.9569035123132822, train_loss: 23.16485595703125, test_acc: 0.6861768368617683, test_P: 0.5916892502258356, test_R: 0.6830031282586028, test_F1: 0.6340755082284608
**train** epoch 21, train_acc: 0.9594771901493743, train_loss: 20.63789176940918, test_acc: 0.6828559568285596, test_P: 0.5951219512195122, test_R: 0.6360792492179353, test_F1: 0.6149193548387096
**train** epoch 22, train_acc: 0.9609911182882519, train_loss: 20.212312698364258, test_acc: 0.6965545869655458, test_P: 0.6142284569138277, test_R: 0.6392075078206465, test_F1: 0.6264690853346959
**train** epoch 23, train_acc: 0.9674000807428341, train_loss: 17.32948112487793, test_acc: 0.6841012868410129, test_P: 0.5885509838998211, test_R: 0.6861313868613139, test_F1: 0.6336061627347135
