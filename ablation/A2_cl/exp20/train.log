-------------------------------hyperparameters---------------------------
lr: 0.0001, temp: 0.2, cl-weight: 0.4, bce-weight:1.0 batch-size: 64, 
-------------------------------------------------------------------------
**train** epoch 0, train_acc: 0.6738494146144529, train_loss: 797.8724975585938, test_acc: 0.688667496886675, test_P: 0.6098843322818086, test_R: 0.6047966631908238, test_F1: 0.6073298429319371
**train** epoch 1, train_acc: 0.6980722648364958, train_loss: 781.7019653320312, test_acc: 0.6953092569530925, test_P: 0.6078619367209971, test_R: 0.6611053180396246, test_F1: 0.6333666333666333
**train** epoch 2, train_acc: 0.7111929753734356, train_loss: 769.7640991210938, test_acc: 0.7114985471149855, test_P: 0.618491921005386, test_R: 0.7184567257559958, test_F1: 0.6647370959961408
**train** epoch 3, train_acc: 0.7210335082761405, train_loss: 756.383056640625, test_acc: 0.7144043171440432, test_P: 0.6799468791500664, test_R: 0.5338894681960376, test_F1: 0.5981308411214953
**train** epoch 4, train_acc: 0.7373334679047234, train_loss: 745.3737182617188, test_acc: 0.70568700705687, test_P: 0.6118067978533095, test_R: 0.7132429614181439, test_F1: 0.6586422725084257
**train** epoch 5, train_acc: 0.7465684295518773, train_loss: 733.7881469726562, test_acc: 0.70568700705687, test_P: 0.6090750436300174, test_R: 0.7278415015641293, test_F1: 0.6631828978622328
**train** epoch 6, train_acc: 0.7613039967702866, train_loss: 720.8384399414062, test_acc: 0.70568700705687, test_P: 0.6085069444444444, test_R: 0.7309697601668405, test_F1: 0.6641402179062056
**train** epoch 7, train_acc: 0.7742733144933387, train_loss: 707.2799072265625, test_acc: 0.7007056870070568, test_P: 0.609375, test_R: 0.6913451511991658, test_F1: 0.6477772349780166
**train** epoch 8, train_acc: 0.7897658457811869, train_loss: 692.029296875, test_acc: 0.7131589871315899, test_P: 0.6434689507494646, test_R: 0.6266944734098019, test_F1: 0.6349709455890121
**train** epoch 9, train_acc: 0.8114654824384336, train_loss: 679.65234375, test_acc: 0.7123287671232876, test_P: 0.6433189655172413, test_R: 0.6225234619395204, test_F1: 0.6327503974562798
**train** epoch 10, train_acc: 0.8224162293096487, train_loss: 667.6099853515625, test_acc: 0.7023661270236613, test_P: 0.6159003831417624, test_R: 0.670490093847758, test_F1: 0.6420369445831253
**train** epoch 11, train_acc: 0.8426019378280177, train_loss: 652.9190063476562, test_acc: 0.7002905770029058, test_P: 0.6227979274611399, test_R: 0.6266944734098019, test_F1: 0.6247401247401247
**train** epoch 12, train_acc: 0.8559245054501413, train_loss: 643.8209838867188, test_acc: 0.6919883769198838, test_P: 0.6433289299867899, test_R: 0.5078206465067779, test_F1: 0.5675990675990676
