-------------------------------hyperparameters---------------------------
lr: 0.0001, temp: 0.6, cl-weight: 0.4, bce-weight:1.0 batch-size: 64, 
-------------------------------------------------------------------------
**train** epoch 0, train_acc: 0.6806116269681066, train_loss: 790.824462890625, test_acc: 0.6940639269406392, test_P: 0.623608017817372, test_R: 0.583941605839416, test_F1: 0.6031233171782445
**train** epoch 1, train_acc: 0.7074081550262414, train_loss: 780.3312377929688, test_acc: 0.6998754669987547, test_P: 0.6154598825831703, test_R: 0.6558915537017727, test_F1: 0.6350328117112569
**train** epoch 2, train_acc: 0.7150787242632216, train_loss: 775.75146484375, test_acc: 0.7135740971357409, test_P: 0.6230558096980787, test_R: 0.7101147028154328, test_F1: 0.6637426900584795
**train** epoch 3, train_acc: 0.7296628986677433, train_loss: 762.6614990234375, test_acc: 0.7144043171440432, test_P: 0.6638452237001209, test_R: 0.5724713242961418, test_F1: 0.6147816349384099
**train** epoch 4, train_acc: 0.7443480016148567, train_loss: 750.6568603515625, test_acc: 0.7040265670402657, test_P: 0.6065857885615251, test_R: 0.7299270072992701, test_F1: 0.6625650733554188
**train** epoch 5, train_acc: 0.7555006055712555, train_loss: 741.5991821289062, test_acc: 0.7085927770859277, test_P: 0.6093617021276596, test_R: 0.7466110531803962, test_F1: 0.6710402999062793
**train** epoch 6, train_acc: 0.7681671376665321, train_loss: 733.39990234375, test_acc: 0.7110834371108343, test_P: 0.6162687886825818, test_R: 0.7267987486965589, test_F1: 0.6669856459330143
**train** epoch 7, train_acc: 0.7843661687525232, train_loss: 723.9102783203125, test_acc: 0.7073474470734745, test_P: 0.6295918367346939, test_R: 0.643378519290928, test_F1: 0.6364105208870552
**train** epoch 8, train_acc: 0.8031388776746063, train_loss: 713.7875366210938, test_acc: 0.7181403071814031, test_P: 0.6483050847457628, test_R: 0.6381647549530761, test_F1: 0.6431949553336836
**train** epoch 9, train_acc: 0.822214372224465, train_loss: 702.2507934570312, test_acc: 0.70942299709423, test_P: 0.6296296296296297, test_R: 0.6558915537017727, test_F1: 0.6424923391215526
**train** epoch 10, train_acc: 0.8325595478401292, train_loss: 692.2760009765625, test_acc: 0.7019510170195101, test_P: 0.6314067611777535, test_R: 0.6037539103232534, test_F1: 0.6172707889125799
**train** epoch 11, train_acc: 0.8550666128381106, train_loss: 678.8905639648438, test_acc: 0.6936488169364882, test_P: 0.6063522617901829, test_R: 0.656934306569343, test_F1: 0.6306306306306306
**train** epoch 12, train_acc: 0.8611223253936213, train_loss: 671.9714965820312, test_acc: 0.6799501867995019, test_P: 0.6649122807017543, test_R: 0.39520333680917624, test_F1: 0.49574885546108566
