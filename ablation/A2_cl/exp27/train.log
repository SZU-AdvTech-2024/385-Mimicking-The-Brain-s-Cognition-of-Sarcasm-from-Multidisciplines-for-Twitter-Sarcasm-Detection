-------------------------------hyperparameters---------------------------
lr: 0.0001, temp: 0.6, cl-weight: 0.1, bce-weight:1.0 batch-size: 64, 
-------------------------------------------------------------------------
**train** epoch 0, train_acc: 0.6848001614856681, train_loss: 337.17041015625, test_acc: 0.7040265670402657, test_P: 0.6481927710843374, test_R: 0.5610010427528676, test_F1: 0.6014533258803801
**train** epoch 1, train_acc: 0.7124041178845377, train_loss: 326.7546691894531, test_acc: 0.7019510170195101, test_P: 0.6223350253807106, test_R: 0.6392075078206465, test_F1: 0.6306584362139918
**train** epoch 2, train_acc: 0.7221941865159467, train_loss: 322.4198913574219, test_acc: 0.7119136571191366, test_P: 0.6214482126489459, test_R: 0.7069864442127216, test_F1: 0.6614634146341464
**train** epoch 3, train_acc: 0.7363746467501009, train_loss: 315.53521728515625, test_acc: 0.7168949771689498, test_P: 0.6879240162822252, test_R: 0.5286757038581856, test_F1: 0.597877358490566
**train** epoch 4, train_acc: 0.7496972143722245, train_loss: 309.75408935546875, test_acc: 0.7036114570361146, test_P: 0.6083112290008842, test_R: 0.7174139728884255, test_F1: 0.6583732057416268
**train** epoch 5, train_acc: 0.7637262817924909, train_loss: 303.8224182128906, test_acc: 0.7048567870485679, test_P: 0.6085814360770578, test_R: 0.7247132429614181, test_F1: 0.6615897191813422
**train** epoch 6, train_acc: 0.7804804198627372, train_loss: 295.92657470703125, test_acc: 0.6944790369447904, test_P: 0.5922249793217536, test_R: 0.7466110531803962, test_F1: 0.6605166051660517
**train** epoch 7, train_acc: 0.8007165926524021, train_loss: 286.61676025390625, test_acc: 0.6903279369032793, test_P: 0.5925282363162467, test_R: 0.7111574556830031, test_F1: 0.6464454976303318
**train** epoch 8, train_acc: 0.818328623334679, train_loss: 276.6711120605469, test_acc: 0.701120797011208, test_P: 0.6359499431171786, test_R: 0.5828988529718456, test_F1: 0.6082698585418934
**train** epoch 9, train_acc: 0.8349818328623335, train_loss: 265.2721862792969, test_acc: 0.7085927770859277, test_P: 0.6288866599799399, test_R: 0.6538060479666319, test_F1: 0.6411042944785276
**train** epoch 10, train_acc: 0.8563282196205086, train_loss: 252.70614624023438, test_acc: 0.6861768368617683, test_P: 0.5883376849434291, test_R: 0.7049009384775808, test_F1: 0.6413662239089184
**train** epoch 11, train_acc: 0.8780278562777554, train_loss: 241.77505493164062, test_acc: 0.7007056870070568, test_P: 0.6271367521367521, test_R: 0.6120959332638165, test_F1: 0.6195250659630607
**train** epoch 12, train_acc: 0.8860012111425111, train_loss: 234.60406494140625, test_acc: 0.6936488169364882, test_P: 0.6627393225331369, test_R: 0.4692387904066736, test_F1: 0.5494505494505495
