-------------------------------hyperparameters---------------------------
lr: 0.0001, temp: 0.4, cl-weight: 0.1, bce-weight:0.9 batch-size: 64, 
-------------------------------------------------------------------------
**train** epoch 0, train_acc: 0.6844469115865967, train_loss: 319.190673828125, test_acc: 0.7023661270236613, test_P: 0.642018779342723, test_R: 0.570385818561001, test_F1: 0.6040861402540033
**train** epoch 1, train_acc: 0.7092753330641905, train_loss: 310.2263488769531, test_acc: 0.6973848069738481, test_P: 0.6118677042801557, test_R: 0.6558915537017727, test_F1: 0.6331152491192753
**train** epoch 2, train_acc: 0.7197214372224465, train_loss: 306.5418701171875, test_acc: 0.7040265670402657, test_P: 0.6060344827586207, test_R: 0.7330552659019812, test_F1: 0.6635205285512034
**train** epoch 3, train_acc: 0.7309245054501413, train_loss: 300.91845703125, test_acc: 0.7127438771274388, test_P: 0.6877637130801688, test_R: 0.5099061522419187, test_F1: 0.5856287425149701
**train** epoch 4, train_acc: 0.7444489301574485, train_loss: 295.5515441894531, test_acc: 0.7077625570776256, test_P: 0.611353711790393, test_R: 0.7299270072992701, test_F1: 0.6653992395437263
**train** epoch 5, train_acc: 0.7592854259184497, train_loss: 290.7007751464844, test_acc: 0.7019510170195101, test_P: 0.6011754827875735, test_R: 0.7466110531803962, test_F1: 0.666046511627907
**train** epoch 6, train_acc: 0.7717501009285426, train_loss: 284.4588928222656, test_acc: 0.6982150269821503, test_P: 0.5971524288107203, test_R: 0.7434827945776851, test_F1: 0.6623316302833256
**train** epoch 7, train_acc: 0.7915825595478402, train_loss: 276.0027160644531, test_acc: 0.6965545869655458, test_P: 0.6137724550898204, test_R: 0.6412930135557873, test_F1: 0.6272310045894951
**train** epoch 8, train_acc: 0.8081348405329027, train_loss: 268.27117919921875, test_acc: 0.7123287671232876, test_P: 0.6458333333333334, test_R: 0.6141814389989573, test_F1: 0.6296098343132015
**train** epoch 9, train_acc: 0.8289765845781187, train_loss: 257.37957763671875, test_acc: 0.7069323370693233, test_P: 0.6649282920469362, test_R: 0.5318039624608968, test_F1: 0.5909617612977984
**train** epoch 10, train_acc: 0.8456297941057731, train_loss: 247.64089965820312, test_acc: 0.6816106268161063, test_P: 0.5895522388059702, test_R: 0.6590198123044838, test_F1: 0.6223535204332841
**train** epoch 11, train_acc: 0.8672789664917239, train_loss: 236.11582946777344, test_acc: 0.6724782067247821, test_P: 0.5668238993710691, test_R: 0.7518248175182481, test_F1: 0.6463469296279695
**train** epoch 12, train_acc: 0.8764634638675818, train_loss: 229.462890625, test_acc: 0.680365296803653, test_P: 0.6740331491712708, test_R: 0.3816475495307612, test_F1: 0.4873501997336884
