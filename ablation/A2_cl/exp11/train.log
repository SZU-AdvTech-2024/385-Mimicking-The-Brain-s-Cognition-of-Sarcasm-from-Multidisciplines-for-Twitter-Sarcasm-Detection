-------------------------------hyperparameters---------------------------
lr: 0.0001, temp: 0.1, cl-weight: 0.1, bce-weight:1.0 batch-size: 64, 
-------------------------------------------------------------------------
**train** epoch 0, train_acc: 0.6757165926524021, train_loss: 343.50384521484375, test_acc: 0.6911581569115816, test_P: 0.6190476190476191, test_R: 0.5828988529718456, test_F1: 0.6004296455424275
**train** epoch 1, train_acc: 0.7005450141299959, train_loss: 330.7285461425781, test_acc: 0.7007056870070568, test_P: 0.6155339805825243, test_R: 0.6611053180396246, test_F1: 0.637506284565108
**train** epoch 2, train_acc: 0.7106378683891804, train_loss: 327.0260009765625, test_acc: 0.7114985471149855, test_P: 0.6213235294117647, test_R: 0.7049009384775808, test_F1: 0.6604787493893503
**train** epoch 3, train_acc: 0.7229006863140897, train_loss: 319.4599304199219, test_acc: 0.7164798671647987, test_P: 0.6864864864864865, test_R: 0.529718456725756, test_F1: 0.5979988228369629
**train** epoch 4, train_acc: 0.7371820750908357, train_loss: 313.5980224609375, test_acc: 0.7048567870485679, test_P: 0.6061643835616438, test_R: 0.7382690302398331, test_F1: 0.6657263751763046
**train** epoch 5, train_acc: 0.7456096083972548, train_loss: 308.15966796875, test_acc: 0.7044416770444167, test_P: 0.6036943744752309, test_R: 0.7497393117831074, test_F1: 0.6688372093023256
**train** epoch 6, train_acc: 0.7589321760193782, train_loss: 301.95892333984375, test_acc: 0.7139892071398921, test_P: 0.6256983240223464, test_R: 0.7007299270072993, test_F1: 0.661091982292179
**train** epoch 7, train_acc: 0.7747779572062979, train_loss: 294.2479248046875, test_acc: 0.6990452469904525, test_P: 0.6065573770491803, test_R: 0.694473409801877, test_F1: 0.6475449684005834
**train** epoch 8, train_acc: 0.7885547032700848, train_loss: 285.4899597167969, test_acc: 0.7106683271066833, test_P: 0.6353305785123967, test_R: 0.6412930135557873, test_F1: 0.6382978723404256
**train** epoch 9, train_acc: 0.8080339119903108, train_loss: 275.6562194824219, test_acc: 0.7127438771274388, test_P: 0.6221408966148216, test_R: 0.7090719499478624, test_F1: 0.6627680311890838
**train** epoch 10, train_acc: 0.8259487283003634, train_loss: 265.3668212890625, test_acc: 0.7007056870070568, test_P: 0.6296296296296297, test_R: 0.602711157455683, test_F1: 0.6158763985082578
**train** epoch 11, train_acc: 0.84764836495761, train_loss: 252.854736328125, test_acc: 0.6915732669157326, test_P: 0.6227272727272727, test_R: 0.5714285714285714, test_F1: 0.5959760739532355
**train** epoch 12, train_acc: 0.8628381106176827, train_loss: 242.6744842529297, test_acc: 0.6982150269821503, test_P: 0.6502590673575129, test_R: 0.5234619395203337, test_F1: 0.5800115540150202
