-------------------------------hyperparameters---------------------------
lr: 0.0001, temp: 0.4, cl-weight: 0.1, bce-weight:1.0 batch-size: 64, 
-------------------------------------------------------------------------
**train** epoch 0, train_acc: 0.6850020185708519, train_loss: 337.7437438964844, test_acc: 0.6990452469904525, test_P: 0.6308724832214765, test_R: 0.5881126173096975, test_F1: 0.6087425796006476
**train** epoch 1, train_acc: 0.7114957610012111, train_loss: 327.7652282714844, test_acc: 0.7007056870070568, test_P: 0.6180555555555556, test_R: 0.6496350364963503, test_F1: 0.6334519572953736
**train** epoch 2, train_acc: 0.7198728300363343, train_loss: 323.4752197265625, test_acc: 0.7073474470734745, test_P: 0.6121908127208481, test_R: 0.7226277372262774, test_F1: 0.6628407460545194
**train** epoch 3, train_acc: 0.730470327008478, train_loss: 317.26519775390625, test_acc: 0.7156496471564965, test_P: 0.6897506925207756, test_R: 0.5192909280500522, test_F1: 0.5925044616299822
**train** epoch 4, train_acc: 0.7458114654824385, train_loss: 311.6907958984375, test_acc: 0.70942299709423, test_P: 0.6129032258064516, test_R: 0.7330552659019812, test_F1: 0.6676163342830009
**train** epoch 5, train_acc: 0.7592349616471538, train_loss: 306.4114074707031, test_acc: 0.7069323370693233, test_P: 0.6095238095238096, test_R: 0.7340980187695516, test_F1: 0.6660359508041628
**train** epoch 6, train_acc: 0.7741219216794509, train_loss: 299.6624450683594, test_acc: 0.6940639269406392, test_P: 0.592809364548495, test_R: 0.7393117831074035, test_F1: 0.6580046403712297
**train** epoch 7, train_acc: 0.7921881308033912, train_loss: 290.52191162109375, test_acc: 0.6774595267745953, test_P: 0.5708722741433022, test_R: 0.7643378519290928, test_F1: 0.6535889433794025
**train** epoch 8, train_acc: 0.8087908760597498, train_loss: 281.9085388183594, test_acc: 0.7102532171025322, test_P: 0.6526315789473685, test_R: 0.5818561001042752, test_F1: 0.6152149944873209
**train** epoch 9, train_acc: 0.8255450141299959, train_loss: 270.41943359375, test_acc: 0.7106683271066833, test_P: 0.6405579399141631, test_R: 0.6225234619395204, test_F1: 0.6314119513484928
**train** epoch 10, train_acc: 0.8436112232539362, train_loss: 258.5700988769531, test_acc: 0.6857617268576173, test_P: 0.5906642728904847, test_R: 0.6861313868613139, test_F1: 0.6348287506029908
**train** epoch 11, train_acc: 0.8678845377472749, train_loss: 246.8548583984375, test_acc: 0.6907430469074305, test_P: 0.6080808080808081, test_R: 0.6277372262773723, test_F1: 0.6177526936890713
**train** epoch 12, train_acc: 0.8802987484860718, train_loss: 236.18443298339844, test_acc: 0.6874221668742216, test_P: 0.6514705882352941, test_R: 0.4619395203336809, test_F1: 0.5405735204392923
