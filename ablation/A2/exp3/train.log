-------------------------------hyperparameters---------------------------
lr: 0.0002, batch-size: 64, 
-------------------------------------------------------------------------
**train** epoch 0, train_acc: 0.6839422688736375, train_loss: 184.32334899902344, test_acc: 0.6998754669987547, test_P: 0.617296222664016, test_R: 0.6475495307612096, test_F1: 0.6320610687022901
**train** epoch 1, train_acc: 0.714826402906742, train_loss: 174.7817840576172, test_acc: 0.6990452469904525, test_P: 0.6551724137931034, test_R: 0.5151199165797706, test_F1: 0.5767659077641565
**train** epoch 2, train_acc: 0.7286536132418248, train_loss: 169.1770782470703, test_acc: 0.7152345371523454, test_P: 0.6318840579710145, test_R: 0.6819603753910324, test_F1: 0.6559679037111334
**train** epoch 3, train_acc: 0.7412696810658054, train_loss: 161.35427856445312, test_acc: 0.70942299709423, test_P: 0.6333676622039135, test_R: 0.6412930135557873, test_F1: 0.6373056994818653
**train** epoch 4, train_acc: 0.7655429955591442, train_loss: 152.83888244628906, test_acc: 0.6982150269821503, test_P: 0.6005199306759099, test_R: 0.7226277372262774, test_F1: 0.6559394226218647
**train** epoch 5, train_acc: 0.7759890997174, train_loss: 146.09359741210938, test_acc: 0.6944790369447904, test_P: 0.5905767668562144, test_R: 0.7580813347236705, test_F1: 0.6639269406392694
**train** epoch 6, train_acc: 0.7935506661283811, train_loss: 137.2768096923828, test_acc: 0.7119136571191366, test_P: 0.6253547776726585, test_R: 0.6892596454640251, test_F1: 0.6557539682539683
**train** epoch 7, train_acc: 0.813837303189342, train_loss: 124.94386291503906, test_acc: 0.6948941469489415, test_P: 0.6076923076923076, test_R: 0.6590198123044838, test_F1: 0.6323161580790395
