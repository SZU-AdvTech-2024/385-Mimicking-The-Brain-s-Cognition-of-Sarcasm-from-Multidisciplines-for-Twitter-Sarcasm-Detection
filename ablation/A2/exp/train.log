-------------------------------hyperparameters---------------------------
lr: 0.0001, batch-size: 64, 
-------------------------------------------------------------------------
**train** epoch 0, train_acc: 0.6844469115865967, train_loss: 184.51962280273438, test_acc: 0.701120797011208, test_P: 0.6582781456953642, test_R: 0.5182481751824818, test_F1: 0.5799299883313885
**train** epoch 1, train_acc: 0.715482438433589, train_loss: 173.9694061279297, test_acc: 0.7073474470734745, test_P: 0.6282828282828283, test_R: 0.64859228362878, test_F1: 0.638276038994356
**train** epoch 2, train_acc: 0.7281489705288655, train_loss: 168.34442138671875, test_acc: 0.7106683271066833, test_P: 0.6217472118959108, test_R: 0.6976016684045881, test_F1: 0.6574938574938575
**train** epoch 3, train_acc: 0.7450545014129996, train_loss: 160.2523956298828, test_acc: 0.7168949771689498, test_P: 0.6686967113276492, test_R: 0.5724713242961418, test_F1: 0.6168539325842697
**train** epoch 4, train_acc: 0.7598405329027049, train_loss: 153.05673217773438, test_acc: 0.7135740971357409, test_P: 0.6237350505979761, test_R: 0.7069864442127216, test_F1: 0.6627565982404692
**train** epoch 5, train_acc: 0.7783609204683084, train_loss: 145.08181762695312, test_acc: 0.7131589871315899, test_P: 0.6259398496240601, test_R: 0.694473409801877, test_F1: 0.6584280771131982
**train** epoch 6, train_acc: 0.796830843762616, train_loss: 135.00698852539062, test_acc: 0.7031963470319634, test_P: 0.6042735042735042, test_R: 0.7372262773722628, test_F1: 0.6641615782057304
**train** epoch 7, train_acc: 0.8213060153411385, train_loss: 123.0526351928711, test_acc: 0.6924034869240349, test_P: 0.5956140350877193, test_R: 0.708029197080292, test_F1: 0.6469747498808956
**train** epoch 8, train_acc: 0.8425010092854259, train_loss: 110.8092269897461, test_acc: 0.6948941469489415, test_P: 0.6214750542299349, test_R: 0.5974973931178311, test_F1: 0.6092503987240829
**train** epoch 9, train_acc: 0.8637969317723052, train_loss: 96.9542236328125, test_acc: 0.7031963470319634, test_P: 0.6177606177606177, test_R: 0.6673618352450469, test_F1: 0.6416040100250626
**train** epoch 10, train_acc: 0.8811566410981025, train_loss: 84.45588684082031, test_acc: 0.6894977168949772, test_P: 0.5921397379912664, test_R: 0.7069864442127216, test_F1: 0.6444866920152091
**train** epoch 11, train_acc: 0.8989200645942672, train_loss: 74.92018127441406, test_acc: 0.6977999169779991, test_P: 0.6039603960396039, test_R: 0.6996871741397289, test_F1: 0.6483091787439613
**train** epoch 12, train_acc: 0.9084578118691966, train_loss: 67.37515258789062, test_acc: 0.6936488169364882, test_P: 0.6536856745479833, test_R: 0.49009384775808135, test_F1: 0.5601907032181168
**train** epoch 13, train_acc: 0.9188029874848607, train_loss: 59.40837097167969, test_acc: 0.6824408468244084, test_P: 0.5872302158273381, test_R: 0.6809176225234619, test_F1: 0.6306132303235152
**train** epoch 14, train_acc: 0.930964876867178, train_loss: 51.94541549682617, test_acc: 0.6787048567870486, test_P: 0.5829596412556054, test_R: 0.6777893639207507, test_F1: 0.626808100289296
